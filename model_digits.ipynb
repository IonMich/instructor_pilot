{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "# disable gpu\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tensorflow.keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load train and test dataset\n",
    "def load_dataset(val_split=0.2):\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\t# split train into train and validation\n",
    "\tn_train = int(trainX.shape[0] * (1-val_split))\n",
    "\ttrainX, valX = trainX[:n_train], trainX[n_train:]\n",
    "\ttrainY, valY = trainY[:n_train], trainY[n_train:]\n",
    "\n",
    "\treturn trainX, trainY, valX, valY, testX, testY\n",
    "\n",
    "def add_salt_pepper_noise(image, prob=0.1):\n",
    "\t\"\"\"randomly flip each pixel in the image with probability = prob\n",
    "\t\n",
    "\teach pixel has integer values in the range 0 to 255, so we flip the pixel \n",
    "\tby subtracting it from 255\n",
    "\t\"\"\"\n",
    "\tflip = np.random.choice([1, 0], size=image.shape, p=[prob, 1-prob])\n",
    "\t# flip the pixel\n",
    "\tnew_image = np.where(flip==1, 255-image, image)\n",
    "\treturn new_image\n",
    "\n",
    "def add_h_line(image, n_lines=1):\n",
    "\t\"\"\"add n_lines horizontal lines to the image\"\"\"\n",
    "\tfor i in range(n_lines):\n",
    "\t\t# choose a random line\n",
    "\t\tline = np.random.randint(0, image.shape[0])\n",
    "\t\t# add the line\n",
    "\t\timage[line, :] = 255\n",
    "\treturn image\n",
    "\n",
    "def add_v_line(image, n_lines=1):\n",
    "\t\"\"\"add n_lines vertical lines to the image\"\"\"\n",
    "\tfor i in range(n_lines):\n",
    "\t\t# choose a random line\n",
    "\t\tline = np.random.randint(0, image.shape[1])\n",
    "\t\t# add the line\n",
    "\t\timage[:, line] = 255\n",
    "\treturn image\n",
    "\n",
    "def add_noise(image, prob_salt_pepper=0.001, prob_h_line=0.1, prob_v_line=0.1):\n",
    "\t\"\"\"add salt and pepper noise and horizontal and vertical lines to the image\"\"\"\n",
    "\timage = add_salt_pepper_noise(image, prob=prob_salt_pepper)\n",
    "\tn_h_lines = np.random.binomial(1, prob_h_line)\n",
    "\timage = add_h_line(image, n_lines=n_h_lines)\n",
    "\tn_v_lines = np.random.binomial(1, prob_v_line)\n",
    "\timage = add_v_line(image, n_lines=n_v_lines)\n",
    "\treturn image.copy()\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(datasets, *args):\n",
    "\tnew_datasets = []\n",
    "\tfor dataset in datasets:\n",
    "\t\t# add noise to the images\n",
    "\t\tnew_dataset = np.zeros(dataset.shape)\n",
    "\t\tfor i in range(len(dataset)):\n",
    "\t\t\tnew_dataset[i] = add_noise(dataset[i], *args)\n",
    "\t\t# convert from integers to floats\n",
    "\t\tnew_dataset = new_dataset.astype('float32')\n",
    "\t\t# normalize to range 0-1\n",
    "\t\tnew_dataset = new_dataset / 255.0\n",
    "\t\tnew_datasets.append(new_dataset.copy())\n",
    "\t# return normalized images\n",
    "\treturn new_datasets\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# add TensorBoard callback\n",
    "\t\n",
    "\timport datetime\n",
    "\n",
    "\tlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\ttensorboard_callback = TensorBoard(\n",
    "\t\tlog_dir=log_dir, \n",
    "\t\tupdate_freq='batch', \n",
    "\t\thistogram_freq=1,\n",
    "\t\t)\n",
    "\t# load dataset\n",
    "\t_trainX, trainY, _valX, valY, _testX, testY = load_dataset(val_split=0.1)\n",
    "\t\n",
    "\t# keep a subset of the training data for validation\n",
    "\t# prepare pixel data\n",
    "\ttrainX, valX, testX = prep_pixels(\n",
    "\t\tdatasets=(_trainX, _valX, _testX),\n",
    "\t\t)\n",
    "\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\t# add early stopping\n",
    "\tfrom tensorflow.keras.callbacks import EarlyStopping\n",
    "\tearly_stopping = EarlyStopping(\n",
    "\t\tmonitor='val_loss',\n",
    "\t\tpatience=10,\n",
    "\t\tverbose=1,\n",
    "\t\tmode='auto',\n",
    "\t\trestore_best_weights=True,\n",
    "\t\t)\n",
    "\t\t\n",
    "\t# fit model\n",
    "\tmodel.fit(\n",
    "\t\ttrainX, \n",
    "\t\ttrainY, \n",
    "\t\tepochs=50,\n",
    "\t\tbatch_size=64,\n",
    "\t\tcallbacks=[tensorboard_callback, early_stopping],\n",
    "\t\tvalidation_data=(valX, valY),\n",
    "\t\t)\n",
    "\t# save model\n",
    "\tmodel.save('new_model.h5')\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step\n",
    "# load dataset\n",
    "_trainX, trainY, _valX, valY, _testX, testY = load_dataset()\n",
    "# prepare pixel data\n",
    "trainX, valX, testX = prep_pixels([_trainX, _valX, _testX])\n",
    "\n",
    "# display example from the dataset\n",
    "from matplotlib import pyplot\n",
    "for i in range(16):\n",
    "    # define subplot\n",
    "    pyplot.subplot(4, 4, i+1)\n",
    "    # turn off axis\n",
    "    pyplot.axis('off')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(_trainX[i], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first few images after the noise is added\n",
    "for i in range(16):\n",
    "    # define subplot\n",
    "    pyplot.subplot(4, 4, i+1)\n",
    "    # turn off axis\n",
    "    pyplot.axis('off')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(trainX[i], cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first few images along with the correct and predicted labels\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('media/classify/new_model.h5')\n",
    "dataset = testX\n",
    "labels = testY # one hot encoded\n",
    "found = 0\n",
    "square = 5\n",
    "for i in range(dataset.shape[0]):\n",
    "    yhat = model.predict(dataset[i].reshape(1, 28, 28, 1))\n",
    "    if np.argmax(yhat) == np.argmax(labels[i]):\n",
    "        color = 'green'\n",
    "        continue\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # define subplot\n",
    "    pyplot.subplot(square, square, found+1)\n",
    "    # turn off axis\n",
    "    pyplot.axis('off')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(dataset[i], cmap='gray_r')\n",
    "    # predict the label\n",
    "    # convert one hot to label\n",
    "    label = np.argmax(yhat)\n",
    "    # display also the correct label as text in black\n",
    "    pyplot.text(0, 0, f\"{np.argmax(labels[i])}\", color='black')\n",
    "    # display the predicted label as text in the color defined above\n",
    "    pyplot.text(0, 7, f\"{label}\", color=color)\n",
    "    found += 1\n",
    "    if found == square**2:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "model = tf.keras.models.load_model('media/classify/digits_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signature = [\n",
    "    tf.TensorSpec([None, 28, 28, 1], dtype=tf.float32)\n",
    "]\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    output_path='media/classify/digits_model.onnx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load the MNIST dataset\n",
    "(_, _), (testX, testY) = mnist.load_data()\n",
    "\n",
    "# select a random image from the test set\n",
    "idx = np.random.randint(0, testX.shape[0])\n",
    "image = testX[idx]\n",
    "print(image.shape)\n",
    "# preprocess the image\n",
    "image = image.astype('float32') / 255.0\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "print(image.shape)\n",
    "\n",
    "# load the ONNX model\n",
    "sess = onnxruntime.InferenceSession('media/classify/digits_model.onnx')\n",
    "\n",
    "# run the model on the image\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "pred = sess.run([output_name], {input_name: image})\n",
    "\n",
    "# print the predicted label\n",
    "print(f\"Predicted label: {np.argmax(pred)}\")\n",
    "# print the true label\n",
    "print(f\"True label: {testY[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the ONNX model\n",
    "%timeit sess.run([output_name], {input_name: image})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('django-tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bd70bfd4d5663c1ff860d0b56fe817ee15536fb7b0cc7b3062f2b0f4009c46c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
